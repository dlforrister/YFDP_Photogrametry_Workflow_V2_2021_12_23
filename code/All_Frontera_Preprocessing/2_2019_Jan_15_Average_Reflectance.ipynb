{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V2 pipeline. Pre process on frontera nd then submit directly to metashape job\n",
    "    Step 1 rclone all files onto scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/08531/dlforr/.local/lib/python3.7/site-packages/setuptools/_importlib.py:23: UserWarning: `importlib-metadata` version is incompatible with `setuptools`.\n",
      "This problem is likely to be solved by installing an updated version of `importlib-metadata`.\n",
      "  warnings.warn(msg)  # Ensure a descriptive message is shown.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "import glob\n",
    "import subprocess\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquisition_month=\"5_2019_Jan\"\n",
    "aquisition_date=\"Jan_15_2019\"\n",
    "aquisition_date_folder=\"2_2019_Jan_15\"\n",
    "drive_base=\"gcloud:2018_Yasuni_Drone_Mapping\"\n",
    "\n",
    "base_folder=\"/scratch1/08531/dlforr/001_image_preprocess\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create the necesarry subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(base_folder)\n",
    "\n",
    "if not os.path.exists(aquisition_date_folder):    \n",
    "    os.mkdir(aquisition_date_folder)\n",
    "    os.mkdir(aquisition_date_folder+\"/Proccessed_Images\")\n",
    "    os.mkdir(aquisition_date_folder+\"/Proccessed_Images/Phantom\")\n",
    "    os.mkdir(aquisition_date_folder+\"/Reflectance\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next clone everyting using rclone\n",
    "\n",
    "1) copy refectance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rclone_path= \"~/src/rclone-v1.57.0-linux-amd64/rclone\"\n",
    "\n",
    "rclone_source = drive_base  + \"/\" + aquisition_month + \"/\" + aquisition_date + \"/Reflectance/\"\n",
    "rclone_dest = \"./\" + aquisition_date_folder+\"/Reflectance/\"\n",
    "\n",
    "#print(rclone_source)\n",
    "#print(rclone_dest)\n",
    "\n",
    "\n",
    "command = rclone_path +\" sync \" +  rclone_source + \" \" + rclone_dest + \" -v\"\n",
    "print(command)\n",
    "\n",
    "!{command}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy Phantom processed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rclone_source = drive_base  + \"/\" + aquisition_month + \"/\" + aquisition_date + \"/Proccessed_Images/Phantom/\"\n",
    "rclone_dest = \"./\" + aquisition_date_folder+\"/Proccessed_Images/Phantom/\"\n",
    "\n",
    "command = rclone_path +\" sync \" +  rclone_source + \" \" + rclone_dest + \" -v\"\n",
    "print(command)\n",
    "\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all necessary data have been copied calculate reflectance and choose a base image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home1/08531/dlforr/github_dir/YFDP_Photogrametry_Workflow_V2_2021_12_23/code\")\n",
    "import functions_calculate_image_average_extract_coordinates as pipeline_functions\n",
    "\n",
    "\n",
    "colors = {'Target':'tab:blue', 1:'tab:orange', 2:'tab:green', 3:'tab:red', 4:'tab:purple', 5:'tab:brown'}\n",
    "\n",
    "def plot_dataset(images_path,reference_path,cam_type):\n",
    "    cam_types = ['Mapir', 'Mapir', 'Stationary']\n",
    "    if cam_type not in cam_types:\n",
    "        raise ValueError(\"Invalid camera type. Expected one of: %s\" % cam_types)\n",
    "\n",
    "    images = pd.read_csv(images_path)\n",
    "    images[\"file_name\"] = images[\"file_name\"].str[:-4]\n",
    "    images = images.sort_values([\"flight\", \"image\"], ascending = (True, True))\n",
    "    images[\"order_all\"] = list(range(1,len(images[\"file_name\"]+1)))\n",
    "    phantom_reflectance[\"file_name\"] = phantom_reflectance[\"file_name\"].str[:-4]\n",
    "    images = pd.read_csv(images_path)\n",
    "    images[\"file_name\"] = images[\"file_name\"].str[:-4]\n",
    "    reference_target = pd.read_csv(images_path)\n",
    "    reference_target = reference_target.sort_values([\"flight\"], ascending = (True))\n",
    "    reference_target[\"order_all\"] = list(range(1,len(phantom_reflectance[\"file_name\"])+1))\n",
    "    reference_target[\"flight\"] = \"Target\"\n",
    "    combined = pd.concat([reference_target,reference_target])\n",
    "    combined = combined.reset_index()\n",
    "    combined[\"date\"] = combined.date.astype(str)\n",
    "    combined[\"date\"] = [dt.datetime.strptime(d,\"%Y:%m:%d %H:%M:%S\") for d in combined[\"date\"]]\n",
    "    #{['Phantom':0, 'Mapir':1, 'Stationary':2]}\n",
    "    \n",
    "    #need to apply function to each type of camera and then plot at once\n",
    "    combined.plot(x=\"date\", y=\"mean_red\", kind=\"scatter\",c=combined['flight'].map(colors),title='Image Reflectance Per Flight', xlabel = \"Time\", ylabel = \"Red Reflectance\", ax=axis[{'Phantom':0, 'Mapir':1, 'Stationary':2}[cam_type]])\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work with Phantom Data:\n",
    "Step 1: Extract image metadata and coordinates from Phantom Images and Calculate averages:\n",
    "Step 2: Read in averages, Remove, file extension Sort images and create an overall order and plot change in reflectance over time/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general path to date folder\n",
    "proj_base_path= base_folder + \"/\" + aquisition_date_folder\n",
    "os.chdir(proj_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing CSV with GPS info for 1953 images\n",
      "--- 0 minutes ---\n"
     ]
    }
   ],
   "source": [
    "phantom_path = './Proccessed_Images/Phantom/'\n",
    "\n",
    "start_time = time.time()\n",
    "if not os.path.exists(phantom_path + \"image_mean_reflectance.csv\"):    \n",
    "    pipeline_functions.calc_image_average(phantom_path)\n",
    "\n",
    "print(\"--- %s minutes ---\" % int((time.time() - start_time)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phantom_images = pd.read_csv(phantom_path + \"image_mean_reflectance.csv\")\n",
    "Phantom_images = Phantom_images.sort_values([\"flight\", \"image\"], ascending = (True, True))\n",
    "Phantom_images[\"order_all\"] = list(range(1,len(Phantom_images[\"file_name\"])+1))\n",
    "Phantom_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in Phantom Reflectance Target Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phantom_Reflectance_path= proj_base_path + '/Reflectance/Phantom/'\n",
    "\n",
    "if not os.path.exists(Phantom_Reflectance_path + \"image_mean_reflectance.csv\"):    \n",
    "    pipeline_functions.calc_image_average(Phantom_Reflectance_path)\n",
    "    \n",
    "\n",
    "phantom_reflectance = pd.read_csv(Phantom_Reflectance_path + \"image_mean_reflectance.csv\")\n",
    "phantom_reflectance = phantom_reflectance.sort_values([\"flight\"], ascending = (True))\n",
    "phantom_reflectance[\"order_all\"] = list(range(1,len(phantom_reflectance[\"file_name\"])+1))\n",
    "phantom_reflectance[\"flight\"] = \"Target\"\n",
    "phantom_reflectance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine Phantom Images with the reflectance target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phantom = pd.concat([phantom_reflectance,Phantom_images])\n",
    "phantom = phantom.reset_index()\n",
    "phantom[\"date\"] = phantom.date.astype(str)\n",
    "phantom[\"date\"]= [dt.datetime.strptime(d,\"%Y:%m:%d %H:%M:%S\") for d in phantom[\"date\"]]\n",
    "phantom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in Stationary Reflectance\n",
    "*note october 2nd the folders are messed up so you have to use this special function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Station_path= proj_base_path + \"/Reflectance/Stationary_Reflectance/\"\n",
    "print(Station_path)\n",
    "\n",
    "start_time = time.time()\n",
    "if not os.path.exists(Station_path + \"image_mean_reflectance.csv\"):\n",
    "    pipeline_functions.calc_image_average_stationary(Station_path)\n",
    "    print(\"--- %s minutes ---\" % (time.time() - start_time))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_refectance = pd.read_csv(Station_path + \"image_mean_reflectance.csv\")\n",
    "stationary_refectance = stationary_refectance.sort_values([\"date\"], ascending = (True))\n",
    "stationary_refectance[\"order_all\"] = list(range(1,len(stationary_refectance[\"file_name\"])+1))\n",
    "\n",
    "stationary_refectance[\"date\"] = stationary_refectance.date.astype(str)\n",
    "stationary_refectance[\"date\"]= [dt.datetime.strptime(d,\"%Y:%m:%d %H:%M:%S\") for d in stationary_refectance[\"date\"]]\n",
    "stationary_refectance[\"flight\"] = 1\n",
    "stationary_refectance[\"image\"] = stationary_refectance[\"order_all\"]\n",
    "stationary_refectance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust Time Stamp values that were messed up due to cameras not being insync\n",
    "\n",
    "Phantom = Correct\n",
    "MAPIR = 3 Hours Early\n",
    "Stationary = Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_added = dt.timedelta(hours = 0)\n",
    "phantom[\"date\"] = phantom[\"date\"]+hours_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phantom_target = phantom[phantom[\"flight\"] == \"Target\"]\n",
    "phantom_target\n",
    "\n",
    "phantom_target.plot(x=\"date\", y=\"mean_red\", kind=\"scatter\",c=phantom_target['flight'].map(colors),title='Phantom', xlabel = \"Time\", ylabel = \"Red Reflectance\")\n",
    "# Make most of the ticklabels empty so the labels don't get too crowded\n",
    "\n",
    "\n",
    "\n",
    "#ticklabels_1 = ['']*len(phantom.index)\n",
    "# Every 4th ticklable shows the month and day\n",
    "#ticklabels_1[::2] = [item.strftime('%H:%M') for item in phantom.date[::2]]\n",
    "#ax_1.xaxis.set_major_formatter(ticker.FixedFormatter(ticklabels_1))\n",
    "#date_form = DateFormatter('%H:%M')\n",
    "#ax_1.xaxis.set_major_formatter(date_form)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(2, 1)\n",
    "\n",
    "# Phantom Data\n",
    "ax_1 = phantom.plot(x=\"date\", y=\"mean_red\", kind=\"scatter\",c=phantom['flight'].map(colors),title='Phantom', xlabel = \"Time\", ylabel = \"Red Reflectance\",ax=axis[0])\n",
    "# Make most of the ticklabels empty so the labels don't get too crowded\n",
    "\n",
    "#ticklabels_1 = ['']*len(phantom.index)\n",
    "# Every 4th ticklable shows the month and day\n",
    "#ticklabels_1[::2] = [item.strftime('%H:%M') for item in phantom.date[::2]]\n",
    "#ax_1.xaxis.set_major_formatter(ticker.FixedFormatter(ticklabels_1))\n",
    "date_form = DateFormatter('%H:%M')\n",
    "ax_1.xaxis.set_major_formatter(date_form)\n",
    "\n",
    "  \n",
    "# stationary_refectance\n",
    "ax_3 = stationary_refectance.plot(x=\"date\", y=\"mean_red\", kind=\"scatter\",c=stationary_refectance['flight'].map(colors),title='Stationary Reflectance', xlabel = \"Time\", ylabel = \"Red Reflectance\",ax=axis[1])\n",
    "# Make most of the ticklabels empty so the labels don't get too crowded\n",
    "#ticklabels_3 = ['']*len(stationary_refectance.index)\n",
    "# Every 4th ticklable shows the month and day\n",
    "#ticklabels_3[::2] = [item.strftime('%H:%M') for item in stationary_refectance.date[::2]]\n",
    "#ax_3.xaxis.set_major_formatter(ticker.FixedFormatter(ticklabels_3))\n",
    "ax_3.xaxis.set_major_formatter(date_form)\n",
    "\n",
    "\n",
    "plt.subplots_adjust(hspace = 1)\n",
    "\n",
    "\n",
    "\n",
    "figure.patch.set_facecolor('white')\n",
    "figure.set_figheight(10)\n",
    "#plt.savefig(proj_base_path + 'Proccessed_Images/1_Raw_Reflectance_2018_Feb_28.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Next Images have to be normalized:\n",
    "\n",
    "Step 1: identify normalization images.\n",
    "\n",
    "Step 2: Normalize data using the following bash/python code\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phantom Images\n",
    "start_time = time.time()\n",
    "\n",
    "sourceFolder = proj_base_path + \"/Proccessed_Images/Phantom\"\n",
    "destImage_rel = \"2019_Jan_15_Phantom_Flight_1_80.JPG\"\n",
    "\n",
    "command = 'sourceFolder=' + sourceFolder + '; ' + 'cd \"${sourceFolder}\"; ' + 'destImage_rel=' + destImage_rel + '; ' + 'destImage=\"${sourceFolder}/${destImage_rel}\"; ' + 'ls *.JPG | xargs -n 1 -P 32 -I @ python3 /home1/08531/dlforr/github_dir/YFDP_Photogrametry_Workflow_V2_2021_12_23/code/normalize_single_image.py -sourceFolder $sourceFolder -destImage $destImage -image @'\n",
    "\n",
    "!{command}\n",
    "print(str(round((time.time() - start_time)/60,2))+ \" minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceFolder = proj_base_path + \"/Proccessed_Images/Phantom/\"\n",
    "sourceFolder_cmd='sourceFolder=' + sourceFolder + ';'\n",
    "sourceFolder_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceFolder = proj_base_path + \"/Proccessed_Images/Phantom/\"\n",
    "command = 'sourceFolder=' + sourceFolder + '; ' + 'cd \"${sourceFolder}\"; ' + '''add_exif() {image=$1; outputname=\"${image/.JPG/_HSV_V_fixed.JPG}\"; output=\"./output/${outputname}\"; echo \"${image}\"; eval \"/home1/08531/dlforr/src/Image-ExifTool-12.44/exiftool -q -q -overwrite_original_in_place -TagsFromFile ${image} $'-all:all>all:all' ${output}\"}; ''' +  'export -f add_exif;' + 'parallel -j8 add_exif {} ::: *.JPG'\n",
    "print(command)\n",
    "#subprocess.call(command,shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all normalized images have been created, we need to add back in the exif data to the normalized images with Exif tools.\n",
    "\n",
    "First add the phantom images back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phantom Images\n",
    "sourceFolder = proj_base_path + \"/Proccessed_Images/Phantom/\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "command = 'sourceFolder=' + sourceFolder + '; ' + 'cd \"${sourceFolder}\"; ' + 'ls *.JPG | xargs -n 1 -P 32 -I {} /home1/08531/dlforr/github_dir/YFDP_Photogrametry_Workflow_V2_2021_12_23/code/simple_add_exif.sh ' + sourceFolder + ' {}'\n",
    "!{command}\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After images have been normalized. Here we create the same graph as above to see how well normalization worked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing CSV with GPS info for 1953 images\n",
      "--- 0 minutes ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file_name</th>\n",
       "      <th>flight</th>\n",
       "      <th>image</th>\n",
       "      <th>date</th>\n",
       "      <th>mean_red</th>\n",
       "      <th>sd_red</th>\n",
       "      <th>mean_green</th>\n",
       "      <th>sd_green</th>\n",
       "      <th>mean_blue</th>\n",
       "      <th>sd_blue</th>\n",
       "      <th>order_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>0</td>\n",
       "      <td>2019_Jan_15_Phantom_Flight_1_36_HSV_V_fixed</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>2019:01:15 08:34:23</td>\n",
       "      <td>82.88</td>\n",
       "      <td>50.17</td>\n",
       "      <td>151.44</td>\n",
       "      <td>59.91</td>\n",
       "      <td>76.17</td>\n",
       "      <td>39.83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>0</td>\n",
       "      <td>2019_Jan_15_Phantom_Flight_1_37_HSV_V_fixed</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>2019:01:15 08:34:25</td>\n",
       "      <td>84.13</td>\n",
       "      <td>49.71</td>\n",
       "      <td>153.95</td>\n",
       "      <td>58.44</td>\n",
       "      <td>78.79</td>\n",
       "      <td>39.09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>0</td>\n",
       "      <td>2019_Jan_15_Phantom_Flight_1_38_HSV_V_fixed</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2019:01:15 08:34:27</td>\n",
       "      <td>89.09</td>\n",
       "      <td>48.92</td>\n",
       "      <td>154.46</td>\n",
       "      <td>58.78</td>\n",
       "      <td>85.26</td>\n",
       "      <td>39.68</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0</td>\n",
       "      <td>2019_Jan_15_Phantom_Flight_1_39_HSV_V_fixed</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2019:01:15 08:34:29</td>\n",
       "      <td>88.37</td>\n",
       "      <td>49.24</td>\n",
       "      <td>153.01</td>\n",
       "      <td>58.99</td>\n",
       "      <td>85.59</td>\n",
       "      <td>40.01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>2019_Jan_15_Phantom_Flight_1_40_HSV_V_fixed</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2019:01:15 08:34:31</td>\n",
       "      <td>89.21</td>\n",
       "      <td>49.58</td>\n",
       "      <td>153.87</td>\n",
       "      <td>59.28</td>\n",
       "      <td>87.37</td>\n",
       "      <td>40.24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>0</td>\n",
       "      <td>2019_Jan_15_Phantom_Flight_5_422_HSV_V_fixed</td>\n",
       "      <td>5</td>\n",
       "      <td>422</td>\n",
       "      <td>2019:01:15 10:12:26</td>\n",
       "      <td>112.34</td>\n",
       "      <td>57.97</td>\n",
       "      <td>153.24</td>\n",
       "      <td>60.77</td>\n",
       "      <td>93.51</td>\n",
       "      <td>48.09</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>0</td>\n",
       "      <td>2019_Jan_15_Phantom_Flight_5_423_HSV_V_fixed</td>\n",
       "      <td>5</td>\n",
       "      <td>423</td>\n",
       "      <td>2019:01:15 10:12:28</td>\n",
       "      <td>113.04</td>\n",
       "      <td>57.28</td>\n",
       "      <td>153.87</td>\n",
       "      <td>59.61</td>\n",
       "      <td>93.58</td>\n",
       "      <td>47.44</td>\n",
       "      <td>1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0</td>\n",
       "      <td>2019_Jan_15_Phantom_Flight_5_424_HSV_V_fixed</td>\n",
       "      <td>5</td>\n",
       "      <td>424</td>\n",
       "      <td>2019:01:15 10:12:30</td>\n",
       "      <td>113.47</td>\n",
       "      <td>57.03</td>\n",
       "      <td>153.81</td>\n",
       "      <td>59.81</td>\n",
       "      <td>95.08</td>\n",
       "      <td>46.77</td>\n",
       "      <td>1951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>0</td>\n",
       "      <td>2019_Jan_15_Phantom_Flight_5_425_HSV_V_fixed</td>\n",
       "      <td>5</td>\n",
       "      <td>425</td>\n",
       "      <td>2019:01:15 10:12:32</td>\n",
       "      <td>110.52</td>\n",
       "      <td>57.19</td>\n",
       "      <td>152.49</td>\n",
       "      <td>59.60</td>\n",
       "      <td>89.12</td>\n",
       "      <td>45.88</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>0</td>\n",
       "      <td>2019_Jan_15_Phantom_Flight_5_426_HSV_V_fixed</td>\n",
       "      <td>5</td>\n",
       "      <td>426</td>\n",
       "      <td>2019:01:15 10:12:34</td>\n",
       "      <td>112.72</td>\n",
       "      <td>56.47</td>\n",
       "      <td>154.13</td>\n",
       "      <td>58.87</td>\n",
       "      <td>92.77</td>\n",
       "      <td>45.43</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1953 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                     file_name  flight  image  \\\n",
       "571            0   2019_Jan_15_Phantom_Flight_1_36_HSV_V_fixed       1     36   \n",
       "1035           0   2019_Jan_15_Phantom_Flight_1_37_HSV_V_fixed       1     37   \n",
       "1464           0   2019_Jan_15_Phantom_Flight_1_38_HSV_V_fixed       1     38   \n",
       "311            0   2019_Jan_15_Phantom_Flight_1_39_HSV_V_fixed       1     39   \n",
       "31             0   2019_Jan_15_Phantom_Flight_1_40_HSV_V_fixed       1     40   \n",
       "...          ...                                           ...     ...    ...   \n",
       "1554           0  2019_Jan_15_Phantom_Flight_5_422_HSV_V_fixed       5    422   \n",
       "1028           0  2019_Jan_15_Phantom_Flight_5_423_HSV_V_fixed       5    423   \n",
       "285            0  2019_Jan_15_Phantom_Flight_5_424_HSV_V_fixed       5    424   \n",
       "754            0  2019_Jan_15_Phantom_Flight_5_425_HSV_V_fixed       5    425   \n",
       "1361           0  2019_Jan_15_Phantom_Flight_5_426_HSV_V_fixed       5    426   \n",
       "\n",
       "                     date  mean_red  sd_red  mean_green  sd_green  mean_blue  \\\n",
       "571   2019:01:15 08:34:23     82.88   50.17      151.44     59.91      76.17   \n",
       "1035  2019:01:15 08:34:25     84.13   49.71      153.95     58.44      78.79   \n",
       "1464  2019:01:15 08:34:27     89.09   48.92      154.46     58.78      85.26   \n",
       "311   2019:01:15 08:34:29     88.37   49.24      153.01     58.99      85.59   \n",
       "31    2019:01:15 08:34:31     89.21   49.58      153.87     59.28      87.37   \n",
       "...                   ...       ...     ...         ...       ...        ...   \n",
       "1554  2019:01:15 10:12:26    112.34   57.97      153.24     60.77      93.51   \n",
       "1028  2019:01:15 10:12:28    113.04   57.28      153.87     59.61      93.58   \n",
       "285   2019:01:15 10:12:30    113.47   57.03      153.81     59.81      95.08   \n",
       "754   2019:01:15 10:12:32    110.52   57.19      152.49     59.60      89.12   \n",
       "1361  2019:01:15 10:12:34    112.72   56.47      154.13     58.87      92.77   \n",
       "\n",
       "      sd_blue  order_all  \n",
       "571     39.83          1  \n",
       "1035    39.09          2  \n",
       "1464    39.68          3  \n",
       "311     40.01          4  \n",
       "31      40.24          5  \n",
       "...       ...        ...  \n",
       "1554    48.09       1949  \n",
       "1028    47.44       1950  \n",
       "285     46.77       1951  \n",
       "754     45.88       1952  \n",
       "1361    45.43       1953  \n",
       "\n",
       "[1953 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(proj_base_path)\n",
    "phantom_path = './Proccessed_Images/Phantom/'\n",
    "\n",
    "start_time = time.time()\n",
    "if not os.path.exists(phantom_path +\"output/\" + \"image_mean_reflectance.csv\"):    \n",
    "    pipeline_functions.calc_image_average(phantom_path,post_norm=True)\n",
    "    \n",
    "if not os.path.exists(phantom_path +\"output/\" + \"images_metadata_gps.csv\"):    \n",
    "    pipeline_functions.extract_gps_metadat_multi_thred(phantom_path +\"output/\")\n",
    "    \n",
    "print(\"--- %s minutes ---\" % int((time.time() - start_time)/60))\n",
    "    \n",
    "    \n",
    "Phantom_images_post_norm = pd.read_csv(phantom_path + \"output/\" \"image_mean_reflectance.csv\")\n",
    "Phantom_images_post_norm = Phantom_images_post_norm.sort_values([\"flight\", \"image\"], ascending = (True, True))\n",
    "Phantom_images_post_norm[\"order_all\"] = list(range(1,len(Phantom_images_post_norm[\"file_name\"])+1))\n",
    "\n",
    "Phantom_images_post_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phantom_post_norm = pd.concat([phantom_reflectance,Phantom_images_post_norm])\n",
    "phantom_post_norm = phantom_post_norm.reset_index()\n",
    "phantom_post_norm[\"date\"] = phantom_post_norm.date.astype(str)\n",
    "phantom_post_norm[\"date\"]= [dt.datetime.strptime(d,\"%Y:%m:%d %H:%M:%S\") for d in phantom_post_norm[\"date\"]]\n",
    "\n",
    "\n",
    "phantom_post_norm[\"GCC\"] = phantom_post_norm[\"mean_green\"]/(phantom_post_norm[\"mean_red\"]+phantom_post_norm[\"mean_green\"]+phantom_post_norm[\"mean_blue\"])\n",
    "phantom_post_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(3, 1)\n",
    "\n",
    "# Phantom Data\n",
    "ax_1 = phantom.plot(x=\"date\", y=\"mean_red\", kind=\"scatter\",c=phantom['flight'].map(colors),title='Phantom', xlabel = \"Time\", ylabel = \"Red Reflectance\",ax=axis[0])\n",
    "# Make most of the ticklabels empty so the labels don't get too crowded\n",
    "date_form = DateFormatter('%H:%M')\n",
    "ax_1.xaxis.set_major_formatter(date_form)\n",
    "\n",
    "# phantom_post_norm Data\n",
    "ax_2 = phantom_post_norm.plot(x=\"date\", y=\"mean_red\", kind=\"scatter\",c=phantom_post_norm['flight'].map(colors),title='Phantom Normalized', xlabel = \"Time\", ylabel = \"Red Reflectance\",ax=axis[1])\n",
    "# Make most of the ticklabels empty so the labels don't get too crowded\n",
    "ax_2.xaxis.set_major_formatter(date_form)\n",
    "  \n",
    "# stationary_refectance\n",
    "ax_3 = stationary_refectance.plot(x=\"date\", y=\"mean_red\", kind=\"scatter\",c=stationary_refectance['flight'].map(colors),title='Stationary Reflectance', xlabel = \"Time\", ylabel = \"Red Reflectance\",ax=axis[2])\n",
    "# Make most of the ticklabels empty so the labels don't get too crowded\n",
    "ax_3.xaxis.set_major_formatter(date_form)\n",
    "\n",
    "\n",
    "plt.subplots_adjust(hspace = 1)\n",
    "\n",
    "figure.patch.set_facecolor('white')\n",
    "figure.set_figheight(10)\n",
    "#plt.savefig(proj_base_path + 'Proccessed_Images/1_Raw_Reflectance_2018_Feb_28.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now sync the folder back up to google drive\n",
    "1) sync reference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rclone_path= \"~/src/rclone-v1.57.0-linux-amd64/rclone\"\n",
    "os.chdir(proj_base_path)\n",
    "rclone_source = \"./Reflectance/\"\n",
    "rclone_dest = drive_base  + \"/\" + aquisition_month + \"/\" + aquisition_date + \"/Reflectance/\"\n",
    "\n",
    "\n",
    "command = rclone_path +\" sync \" +  rclone_source + \" \" + rclone_dest + \" -v\"\n",
    "\n",
    "\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now copy all phantom processed image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rclone_source = proj_base_path +\"/Proccessed_Images/Phantom/\"\n",
    "rclone_dest = drive_base  + \"/\" + aquisition_month + \"/\" + aquisition_date + \"/Proccessed_Images/Phantom/\"\n",
    "\n",
    "\n",
    "command = rclone_path +\" sync \" +  rclone_source + \" \" + rclone_dest + \" -v\"\n",
    "print(rclone_dest)\n",
    "\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next build project base folder in scractch and copy images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "os.chdir(\"/scratch1/08531/dlforr/000_metashape_projects\")\n",
    "\n",
    "if not os.path.exists(aquisition_date_folder):    \n",
    "    os.mkdir(aquisition_date_folder)\n",
    "    os.mkdir(aquisition_date_folder + \"/images\")\n",
    "         \n",
    "src_dir= proj_base_path + \"/Proccessed_Images/Phantom/output/\"       \n",
    "dst_dir= \"/scratch1/08531/dlforr/000_metashape_projects/\"+ aquisition_date_folder+ \"/images/\"\n",
    "                \n",
    "          \n",
    "for jpgfile in os.listdir(src_dir):\n",
    "    if jpgfile.endswith(\".JPG\"):\n",
    "        shutil.copy(os.path.join(src_dir, jpgfile), dst_dir) \n",
    "\n",
    "         \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
